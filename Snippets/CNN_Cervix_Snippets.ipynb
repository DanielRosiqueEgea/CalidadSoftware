{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roxoner44/CalidadSoftware/blob/main/Snippets/CNN_Cervix_Snippets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh4I-uCDHgcE"
      },
      "outputs": [],
      "source": [
        "#Cargar Datos CNN Cervix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El uso de este colab es el de definir funciones y snipets que vamos a poder usar desde otros colabs, para no tener que caragrlos siempre"
      ],
      "metadata": {
        "id": "8zGt-8XfSAkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importar librerias CNN"
      ],
      "metadata": {
        "id": "W6Prx-BzJhnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#Montamos el drive en el directorio /content/drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "%pip install -q -U keras-tuner\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#KERAS\n",
        "from keras import Sequential\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout, BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "#UTILS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "QUA90yjkHo5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c940131f-5cff-4bb2-bff8-13fb4f8f9861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carga de datos CNN como DataFrame"
      ],
      "metadata": {
        "id": "VF-EZe0pTeH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a definir dos tipos de cargas de datos, por DataFrame y por Directory.\n",
        "\n",
        "Esto para poder escoger si cargar los datos como \"one-hot encoding\" o con \"label encoding\""
      ],
      "metadata": {
        "id": "z6yecAe-Too0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Funciones para la carga de datos"
      ],
      "metadata": {
        "id": "R31qw_fKVYEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cargarDataframeBinario(data):\n",
        "  \"\"\"\n",
        "  Función que carga el dataframe con dos clases (benigna y altogrado) en lugar de con las clases originales\n",
        "\n",
        "  Parameters:\n",
        "    data (posixPath): path desde donde vamos a cargar las imagenes\n",
        "\n",
        "  Returns:\n",
        "    pandasDataframe: dataframe que contiene dos columnas (path y category) con todos los paths de las imagenes y sus categorias en formato binario (label encoding)\n",
        "\n",
        "  \"\"\"\n",
        "  #Guardamos todos los paths que existen en el directorio que queremos\n",
        "  lst = list(data.glob(\"*/*.tiff\"))\n",
        "  #Cramos una nueva lista\n",
        "  newLst = list() \n",
        "  #Para cada elemento de la lista de paths (Por cada imagen)\n",
        "  for l in lst:\n",
        "      #Si el directorio en el que se encuentra es \"benigna\" significa que la celula no es revisable\n",
        "      if l.parent == data / \"benigna\":\n",
        "        tipo=\"No Revisable\"\n",
        "      #El resto son revisables\n",
        "      else:\n",
        "        tipo=\"Revisable\"\n",
        "      #Añade en la lista el tipo y el path de la imagen\n",
        "      newLst.append((str(l),tipo))\n",
        "  #Devuelve el dataframe generado a partir de la lista\n",
        "  return  pd.DataFrame(newLst, columns = ['path', 'category'])\n",
        "\n",
        "def cargarDataFrameCuatroClases(data):\n",
        "  \"\"\"\n",
        "  Función que carga el dataframe con las clases originales\n",
        "\n",
        "  Parameters:\n",
        "    data (posixPath): path desde donde vamos a cargar las imagenes\n",
        "\n",
        "  Returns:\n",
        "    pandasDataframe: dataframe que contiene dos columnas (path y category) con todos los paths de las imagenes y sus categorias en formato binario (label encoding)\n",
        "\n",
        "  \"\"\"\n",
        "  #Guardamos todos los paths que existen en el directorio que queremos\n",
        "  lst = list(data.glob(\"*/*.tiff\"))\n",
        "  #Cramos una nueva lista\n",
        "  newLst = list() \n",
        "  #Para cada elemento de la lista de paths (Por cada imagen)\n",
        "  for l in lst:\n",
        "    #Guarda el tipo como el nombre del directorio en el que se encuentra\n",
        "    tipo=l.parent.name\n",
        "     #Añade en la lista el tipo y el path de la imagen\n",
        "    newLst.append((str(l),tipo)) #Devuelve el dataframe generado a partir de la lista\n",
        "  return  pd.DataFrame(newLst, columns = ['path', 'category'])"
      ],
      "metadata": {
        "id": "7HuNtvuTVXak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def  cargarDatosDataframe(num_classes :int, path = \"/content/drive/My Drive/cérvix - proyecto/Celulas\",pathResults=\"/content/drive/MyDrive/ucam/Investigación/resultados\", batch_size : int =32,img_height :(int)=223,img_width: (int)=244):\n",
        "  \"\"\"Funcion que carga datos desde un dataframe, en contrario a cargarlo desde directorio directamente\n",
        "\n",
        "  Parameters:\n",
        "  num_classes (int): El numero de clases con las cuales se va a generar el dataframe (2 o 4)\n",
        "  path: directorio en el cual se encuentran las imagenes originales que se van a cargar\n",
        "  pathResults: directorio en el cual se van a enviar las imagenes de resultado (Si es que las hubiera)\n",
        "  batch_size (int) =32: tamaño del batch de imagenes que vamos a usar, por defecto 32\n",
        "  img_height (int)=223: alto de las imagenes que queremos\n",
        "  img_width (int)=244: ancho de las imagenes que queremos\n",
        "\n",
        "\n",
        "  Returns:\n",
        "  train_generator : generator de las imagenes de entrenamiento a partir de dataframe\n",
        "  validation_generator : generator de las imagenes de validacion a partir de dataframe\n",
        "  test_generator : generator de las imagenes de test a partir de dataframe\n",
        "  \n",
        "  \"\"\"\n",
        "  CELULASPATH = path\n",
        "  RESULTADOSPATH =pathResults\n",
        "  #Guardamos el path en el cual se encuentran las imagenes de entrenamiento\n",
        "  data_train = pathlib.Path(CELULASPATH + \"/entrenamiento\")\n",
        "\n",
        "  if(num_classes==4):\n",
        "    df = cargarDataframeBinario(data_train)\n",
        "  else:\n",
        "    df = cargarDataFrameCuatroClases(data_train)\n",
        "\n",
        "  print(df.size())\n",
        "  print(df.groupby('category').size())\n",
        "\n",
        "  #Reescalamos los datos\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      horizontal_flip = True,\n",
        "      vertical_flip = True,\n",
        "      validation_split = 0.1)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_dataframe(\n",
        "      df,\n",
        "      x_col = \"path\",\n",
        "      y_col=\"category\",\n",
        "      target_size = (img_height, img_width),\n",
        "      batch_size = batch_size,\n",
        "      shuffle = True,\n",
        "      class_mode = 'sparse', #vamos a usar probar con binary\n",
        "      subset = 'training',\n",
        "      seed = 42)\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_dataframe(\n",
        "      df,\n",
        "      x_col = \"path\",\n",
        "      y_col=\"category\",\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      class_mode='sparse',\n",
        "      subset='validation',\n",
        "      seed=42) # set as validation data\n",
        "\n",
        "  #Guardamos el path en el cual se encuentran las imagenes de test\n",
        "  data_test= pathlib.Path(CELULASPATH + \"/test\")\n",
        "\n",
        "  #Reescalamos los datos\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  test_generator = test_datagen.flow_from_dataframe(df_test,x_col = \"path\",y_col=\"category\",\n",
        "                                                target_size=(224, 224),\n",
        "                                                batch_size=1,\n",
        "                                                shuffle=True,\n",
        "                                             class_mode='sparse')\n",
        "\n",
        "  return train_generator,validation_generator,test_generator"
      ],
      "metadata": {
        "id": "Oo6Ne9MnTeYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CargarDatos directory"
      ],
      "metadata": {
        "id": "5yJIKzhrZgRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Funciones para cargar los datos"
      ],
      "metadata": {
        "id": "m0k4TLT6ZlOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  cargarDatosDirectory(path = \"/content/drive/My Drive/cérvix - proyecto/Celulas\",pathResults=\"/content/drive/MyDrive/ucam/Investigación/resultados\", batch_size : int =32,img_height :(int)=223,img_width: (int)=244):\n",
        "  \"\"\"Funcion que carga datos desde un directorio, te ccarga todas las imagenes que encuentre y guarda el label como el nombre del directorio\n",
        "\n",
        "  Parameters:\n",
        "  path: directorio en el cual se encuentran las imagenes originales que se van a cargar\n",
        "  pathResults: directorio en el cual se van a enviar las imagenes de resultado (Si es que las hubiera)\n",
        "  batch_size (int) =32: tamaño del batch de imagenes que vamos a usar, por defecto 32\n",
        "  img_height (int)=223: alto de las imagenes que queremos\n",
        "  img_width (int)=244: ancho de las imagenes que queremos\n",
        "\n",
        "\n",
        "  Returns:\n",
        "  train_generator : generator de las imagenes de entrenamiento a partir de directorio\n",
        "  validation_generator : generator de las imagenes de validacion a partir de directorio\n",
        "  test_generator : generator de las imagenes de test a partir de directorio\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  CELULASPATH = path\n",
        "  RESULTADOSPATH =pathResults\n",
        "\n",
        "  #Guardamos el path en el cual se encuentran las imagenes de entrenamiento\n",
        "  data_train = pathlib.Path(CELULASPATH + \"/entrenamiento\")\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "  #Reescalamos los datos\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      horizontal_flip = True,\n",
        "      vertical_flip = True,\n",
        "      validation_split = 0.1)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      data_train,\n",
        "      target_size = (img_height, img_width),\n",
        "      batch_size = batch_size,\n",
        "      shuffle = True,\n",
        "      class_mode = 'categorical',\n",
        "      subset = 'training',\n",
        "      seed = 42)\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_directory(\n",
        "      data_train, # same directory as training data\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      class_mode='categorical',\n",
        "      subset='validation',\n",
        "      seed=42) # set as validation data\n",
        "\n",
        "  #Guardamos el path en el cual se encuentran las imagenes de test\n",
        "  data_test= pathlib.Path(CELULASPATH + \"/test\")\n",
        "\n",
        "  #Reescalamos los datos\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(data_test,\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=1,\n",
        "                                                  shuffle=False,\n",
        "  class_mode='categorical')\n",
        "\n",
        "  return train_generator,validation_generator,test_generator"
      ],
      "metadata": {
        "id": "3dWK0UHVZnm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definir funciones para mostrar imagenes CNN"
      ],
      "metadata": {
        "id": "kLYw5atLIQwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def mostrarConLabel(image_arr):\n",
        "    x,y = image_arr.next()\n",
        "    for i in range(0,3):\n",
        "      image = x[i]\n",
        "      label = y[i]\n",
        "      print (label)\n",
        "      plt.imshow(image)\n",
        "      plt.show()\n",
        "\n",
        "def mostrarConLabelMejor(image_arr,class_names):\n",
        "  x,y = image_arr.next()\n",
        "  plt.figure(figsize=(20,20))\n",
        "  for i in range(10):\n",
        "      plt.subplot(5,5,i+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(x[i])\n",
        "      for j in range(4):\n",
        "         if(y[i][j]==1): break\n",
        "      plt.title(class_names[j])\n",
        "      \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lBNR7IyBHo5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mostrar datos"
      ],
      "metadata": {
        "id": "8dhYcDbn7tov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Recibe el history generado\n",
        "def mostrarGrafico(history):\n",
        "  acc      = history.history['accuracy' ]\n",
        "  val_acc  = history.history[ 'val_accuracy' ]\n",
        "  loss     = history.history[    'loss' ]\n",
        "  val_loss = history.history['val_loss' ]\n",
        "\n",
        "  epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
        "\n",
        "  plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
        "  plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
        "  plt.title ('Training and validation accuracy')\n",
        "  plt.ylabel('acc')\n",
        "  plt.xlabel('epochs')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot  ( epochs,     loss, 'r--' , label=\"Training Loss\")\n",
        "  plt.plot  ( epochs, val_loss ,  'b', label=\"Validation loss\")\n",
        "  plt.title ('Training and validation loss'   )\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.show()\n",
        "def mostrarMatrizConf(test_predict,test_generator, class_names):\n",
        "  \n",
        "  predict = []\n",
        "\n",
        "  for i in test_predict:\n",
        "    predict.append(int(np.argmax(i)))\n",
        "\n",
        "  predict = np.asarray(predict)\n",
        "\n",
        "  accuracy = accuracy_score(test_generator.classes, np.asarray(predict))\n",
        "  print(accuracy)\n",
        "\n",
        "  cm = confusion_matrix(test_generator.classes, predict)\n",
        "\n",
        "  cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = class_names,)\n",
        "\n",
        "  cm_display.plot(cmap = 'YlOrRd' )\n",
        "  plt.show()\n",
        "\n",
        "  #plt.figure(figsize = (10,10))\n",
        "  #sns.heatmap(cm, annot=True, cmap='YlGn', xticklabels=class_names, yticklabels=class_names)\n",
        "  #plt.show()\n",
        "def calcularHistorial(model,history,validation_generator,test_generator,validation_steps):\n",
        "\n",
        "  val_acc_per_epoch = history.history['val_accuracy']\n",
        "  best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch))+1\n",
        "  print('Mejor epoca: %d' % (best_epoch,))\n",
        "\n",
        "  eval_result = model.evaluate(validation_generator, steps =validation_steps, verbose =1)\n",
        "  \n",
        "  print(\"[test loss, test accuracy]:\", eval_result)\n",
        "  test_predict = model.predict(test_generator, steps = test_generator.n // 1, verbose =1)\n",
        "  class_names = list(validation_generator.class_indices.keys())\n",
        "  mostrarMatrizConf(test_predict,test_generator,class_names)\n",
        "  mostrarGrafico(history)\n"
      ],
      "metadata": {
        "id": "xiMr4KKSHo5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createBasicModel(num_classes: (int)=4, img_height: (int) = 244,img_width: (int)=244):\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\",input_shape=(img_height,img_width,3)),\n",
        "      layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "      layers.MaxPooling2D(2, 2),\n",
        "      layers.Dropout(0.25),\n",
        "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "      layers.Conv2D(64, 3, activation='relu'),\n",
        "      layers.MaxPooling2D(2, 2),\n",
        "      layers.Dropout(0.25),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(512, activation='relu'),\n",
        "      layers.Dropout(0.1),\n",
        "      layers.Dense(4, activation =\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "  learning_rate=0.0001\n",
        "\n",
        "  model.compile(optimizer= keras.optimizers.RMSprop(lr=learning_rate, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "  #model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "jXo0QY7THo5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definimos las funciones para el modelo CNN"
      ],
      "metadata": {
        "id": "PBWx0NDuIeis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ejemplo_ejecución():\n",
        "  \"\"\"\n",
        "  batch_size = 32\n",
        "  img_height = 244\n",
        "  image_width = 244\n",
        "  train_generator, validation_generator,test_generator = cargarDatosDirectory()\n",
        "\n",
        "  steps_per_epoch = train_generator.n // batch_size\n",
        "  print(\"Train Steps: \"+str(steps_per_epoch)+ \" Train Data: \"+ str(train_generator.n)+ \" Batch: \"+ str(batch_size))\n",
        "  validation_steps = validation_generator.n // batch_size\n",
        "  print(\"Validation Steps: \"+str(validation_steps)+ \" Validation Data: \"+ str(validation_generator.n)+ \" Batch: \"+ str(batch_size))\n",
        "\n",
        "  model = createBasicModel()\n",
        "  history = model.fit(train_generator,epochs=20,validation_data=validation_generator,validation_steps=validation_steps, shuffle=False)\n",
        "  calcularHistorial(model,history,validation_generator,test_generator)\n",
        "  \"\"\"\n",
        "\n",
        "  batch_size = 32\n",
        "  img_height = 244\n",
        "  img_width = 244\n",
        "  train_generator, validation_generator,test_generator = cargarDatosDirectory()\n",
        "\n",
        "  steps_per_epoch = train_generator.n // batch_size\n",
        "  print(\"Train Steps: \"+str(steps_per_epoch)+ \" Train Data: \"+ str(train_generator.n)+ \" Batch: \"+ str(batch_size))\n",
        "  validation_steps = validation_generator.n // batch_size\n",
        "  print(\"Validation Steps: \"+str(validation_steps)+ \" Validation Data: \"+ str(validation_generator.n)+ \" Batch: \"+ str(batch_size))\n",
        "\n",
        "  model = createBasicModel(img_height,img_width)\n",
        "  history = model.fit(train_generator,epochs=20,validation_data=validation_generator,validation_steps=validation_steps, shuffle=False)\n",
        "  calcularHistorial(model,history,validation_generator,test_generator)\n"
      ],
      "metadata": {
        "id": "Eu5ndvK6Ho5Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}